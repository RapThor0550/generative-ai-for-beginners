{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RapThor0550/generative-ai-for-beginners/blob/main/fooocus_colab-Live%20Portrait.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KwaiVGI/LivePortrait.git\n",
        "%cd LivePortrait\n"
      ],
      "metadata": {
        "id": "bVZWLzFve0Qf",
        "outputId": "f15ca466-7b48-4716-9110-75a307e68c89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LivePortrait'...\n",
            "remote: Enumerating objects: 1049, done.\u001b[K\n",
            "remote: Counting objects: 100% (602/602), done.\u001b[K\n",
            "remote: Compressing objects: 100% (363/363), done.\u001b[K\n",
            "remote: Total 1049 (delta 396), reused 240 (delta 239), pack-reused 447 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1049/1049), 38.79 MiB | 25.96 MiB/s, done.\n",
            "Resolving deltas: 100% (507/507), done.\n",
            "/content/LivePortrait\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "sKD3lElce4wb",
        "outputId": "0133bb79-b5e8-4cbf-aa7a-7c5ca25630ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KwaiVGI/LivePortrait.git\n",
        "%cd LivePortrait\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "wfQnNiApfK3n",
        "outputId": "eb3aa462-526f-4929-b693-7ce7542ffbad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LivePortrait' already exists and is not an empty directory.\n",
            "/content/LivePortrait\n",
            "app_animals.py\tinference_animals.py  pretrained_weights  requirements_base.txt   speed.py\n",
            "app.py\t\tinference.py\t      readme.md\t\t  requirements_macOS.txt  src\n",
            "assets\t\tLICENSE\t\t      readme_zh_cn.md\t  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "L6ZBiRikf001",
        "outputId": "92e4fd4f-c187-4617-dd0f-d803c17c14e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LivePortrait\n",
            "app_animals.py\tinference_animals.py  pretrained_weights  requirements_base.txt   speed.py\n",
            "app.py\t\tinference.py\t      readme.md\t\t  requirements_macOS.txt  src\n",
            "assets\t\tLICENSE\t\t      readme_zh_cn.md\t  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LivePortrait\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "CV3qoe6Ef7tO",
        "outputId": "f8d74a3d-0d9a-43c0-9ccf-255bbe696b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'LivePortrait'\n",
            "/content/LivePortrait\n",
            "app_animals.py\tinference_animals.py  pretrained_weights  requirements_base.txt   speed.py\n",
            "app.py\t\tinference.py\t      readme.md\t\t  requirements_macOS.txt  src\n",
            "assets\t\tLICENSE\t\t      readme_zh_cn.md\t  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "cfMFCUE6gBJv",
        "outputId": "462785be-65ea-45f9-9e73-20d2beb5becd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pyyaml==6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: opencv-python==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: imageio==2.34.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 5)) (2.34.2)\n",
            "Requirement already satisfied: lmdb==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 7)) (4.66.4)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 8)) (13.7.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: onnx==1.16.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 10)) (1.16.1)\n",
            "Requirement already satisfied: scikit-image==0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 11)) (0.24.0)\n",
            "Requirement already satisfied: albumentations==1.4.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 12)) (1.4.10)\n",
            "Requirement already satisfied: matplotlib==3.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 13)) (3.9.0)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 14)) (0.5.1)\n",
            "Requirement already satisfied: tyro==0.8.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 15)) (0.8.5)\n",
            "Requirement already satisfied: gradio==5.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 16)) (5.1.0)\n",
            "Requirement already satisfied: pykalman==0.9.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 17)) (0.9.7)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 18)) (10.4.0)\n",
            "Requirement already satisfied: onnxruntime-gpu==1.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.18.0)\n",
            "Requirement already satisfied: transformers==4.38.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.38.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r requirements_base.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r requirements_base.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python==0.2.0->-r requirements_base.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx==1.16.1->-r requirements_base.txt (line 10)) (4.25.6)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (2.10.6)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio-ffmpeg==0.5.1->-r requirements_base.txt (line 14)) (75.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro==0.8.5->-r requirements_base.txt (line 15)) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro==0.8.5->-r requirements_base.txt (line 15)) (1.7.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.9.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.34.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (25.1.24)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (0.5.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (12.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore>=0.0.11->albumentations==1.4.10->-r requirements_base.txt (line 12)) (3.11.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore>=0.0.11->albumentations==1.4.10->-r requirements_base.txt (line 12)) (6.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (0.45.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->-r requirements_base.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r requirements_base.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r requirements_base.txt (line 12)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r requirements_base.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r requirements_base.txt (line 12)) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.1.0->-r requirements_base.txt (line 16)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.5.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "id": "VbyQCAMbgBoC",
        "outputId": "3a8e0aa6-63b3-442e-c72b-4f5b8428aaa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download KwaiVGI/LivePortrait --local-dir pretrained_weights --exclude \"*.git*\" \"README.md\" \"docs\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tFqTJ7o7gTLy",
        "outputId": "2eee6b06-46da-47a2-96bc-21821c0eaa6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 20 files:   0% 0/20 [00:00<?, ?it/s]Downloading 'docs/showcase2.gif' to 'pretrained_weights/.cache/huggingface/download/docs/ovU00xd4wrM1WlqZO5_wVkCk_ec=.eb1fffb139681775780b2956e7d0289f55d199c1a3e14ab263887864d4b0d586.incomplete'\n",
            "Downloading 'insightface/models/buffalo_l/det_10g.onnx' to 'pretrained_weights/.cache/huggingface/download/insightface/models/buffalo_l/J2T53Etq4hZrLiuL9o-I5uPf3dU=.5838f7fe053675b1c7a08b633df49e7af5495cee0493c7dcf6697200b85b5b91.incomplete'\n",
            "Downloading 'insightface/models/buffalo_l/2d106det.onnx' to 'pretrained_weights/.cache/huggingface/download/insightface/models/buffalo_l/maPQ8fYWKyJky9lfTz9beisoSeo=.f001b856447c413801ef5c42091ed0cd516fcd21f2d6b79635b1e733a7109dbf.incomplete'\n",
            "Downloading 'liveportrait/base_models/spade_generator.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait/base_models/7eKjApaVmkkjxwgjxli7XtNsnxU=.4780afc7909a9f84e24c01d73b31a555ef651521a1fe3b2429bd04534d992aee.incomplete'\n",
            "Downloading 'docs/inference.gif' to 'pretrained_weights/.cache/huggingface/download/docs/ke8qy6KU2hXc8UMbe9pzGl7iH4Q=.e1316eca5556ba5a8da7c53bcadbc1df26aa822bbde68fbad94813139803d0c6.incomplete'\n",
            "\n",
            "showcase2.gif:   0% 0.00/2.88M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "2d106det.onnx:   0% 0.00/5.03M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "det_10g.onnx:   0% 0.00/16.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:   0% 0.00/222M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "inference.gif: 100% 820k/820k [00:00<00:00, 20.6MB/s]\n",
            "Download complete. Moving file to pretrained_weights/docs/inference.gif\n",
            "Fetching 20 files:   5% 1/20 [00:00<00:06,  2.88it/s]\n",
            "showcase2.gif: 100% 2.88M/2.88M [00:00<00:00, 19.3MB/s]\u001b[A\n",
            "\n",
            "showcase2.gif: 100% 2.88M/2.88M [00:00<00:00, 18.5MB/s]\n",
            "Download complete. Moving file to pretrained_weights/docs/showcase2.gif\n",
            "2d106det.onnx: 100% 5.03M/5.03M [00:00<00:00, 36.2MB/s]\n",
            "Download complete. Moving file to pretrained_weights/insightface/models/buffalo_l/2d106det.onnx\n",
            "Downloading 'liveportrait/landmark.onnx' to 'pretrained_weights/.cache/huggingface/download/liveportrait/NFbC2M7-BGmftQYQOC0ieXTS16o=.31d22a5041326c31f19b78886939a634a5aedcaa5ab8b9b951a1167595d147db.incomplete'\n",
            "Downloading 'liveportrait/retargeting_models/stitching_retargeting_module.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait/retargeting_models/PNlJHjZewqMDsCN59DNOOoYQIJw=.3652d5a3f95099141a56986aaddec92fadf0a73c87a20fac9a2c07c32b28b611.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "det_10g.onnx:  62% 10.5M/16.9M [00:00<00:00, 41.0MB/s]\u001b[A\u001b[A\u001b[ADownloading 'liveportrait_animals/base_models/appearance_feature_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models/w2JquOgGo_-zOZp03SpATaJOQmc=.e2cd1d5d67c0457229e9736d401d39225e096895b869f34234978082561af6de.incomplete'\n",
            "\n",
            "landmark.onnx:   0% 0.00/115M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "stitching_retargeting_module.pth:   0% 0.00/2.39M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "stitching_retargeting_module.pth: 100% 2.39M/2.39M [00:00<00:00, 41.3MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/retargeting_models/stitching_retargeting_module.pth\n",
            "\n",
            "\n",
            "\n",
            "det_10g.onnx: 100% 16.9M/16.9M [00:00<00:00, 40.9MB/s]\n",
            "Download complete. Moving file to pretrained_weights/insightface/models/buffalo_l/det_10g.onnx\n",
            "Fetching 20 files:  20% 4/20 [00:00<00:02,  6.24it/s]\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:00<00:00, 43.1MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models/appearance_feature_extractor.pth\n",
            "Downloading 'liveportrait_animals/base_models/motion_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models/K0D9rBQicolH41TOWUpuFUb_e4U=.63c0d450099ef6ebece788ab711cb012509712e23fd1200b79fb65ef980adbb9.incomplete'\n",
            "\n",
            "landmark.onnx:   9% 10.5M/115M [00:00<00:02, 42.1MB/s]\u001b[ADownloading 'liveportrait_animals/base_models/spade_generator.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models/7eKjApaVmkkjxwgjxli7XtNsnxU=.7fafa1e31c7c72c9384310d679e32af3fbf214e241fb657df8c3b18ad826f336.incomplete'\n",
            "\n",
            "\n",
            "motion_extractor.pth:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:   0% 0.00/222M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:   9% 21.0M/222M [00:00<00:06, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  18% 21.0M/115M [00:00<00:02, 38.1MB/s]\u001b[A\n",
            "\n",
            "motion_extractor.pth:   9% 10.5M/113M [00:00<00:02, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:   5% 10.5M/222M [00:00<00:04, 43.0MB/s]\u001b[A\u001b[A\u001b[ADownloading 'liveportrait/base_models/warping_module.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait/base_models/Kiu2mTGiqawQvwJIysiPiwdDHsY=.2f61a6f265fe344f14132364859a78bdbbc2068577170693da57fb96d636e282.incomplete'\n",
            "Downloading 'liveportrait/base_models/motion_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait/base_models/K0D9rBQicolH41TOWUpuFUb_e4U=.251e6a94ad667a1d0c69526d292677165110ef7f0cf0f6d199f0e414e8aa0ca5.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  14% 31.5M/222M [00:00<00:05, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'liveportrait/base_models/appearance_feature_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait/base_models/w2JquOgGo_-zOZp03SpATaJOQmc=.5279bb8654293dbdf327030b397f107237dd9212fb11dd75b83dfb635211ceb5.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   0% 0.00/182M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth:   0% 0.00/3.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  19% 21.0M/113M [00:00<00:02, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:   9% 21.0M/222M [00:00<00:04, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  27% 31.5M/115M [00:00<00:02, 34.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:00<00:00, 32.8MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/base_models/appearance_feature_extractor.pth\n",
            "Fetching 20 files:  25% 5/20 [00:01<00:04,  3.01it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   6% 10.5M/182M [00:00<00:04, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   9% 10.5M/113M [00:00<00:02, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  28% 31.5M/113M [00:00<00:01, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  14% 31.5M/222M [00:00<00:04, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  37% 41.9M/115M [00:01<00:01, 37.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  24% 52.4M/222M [00:01<00:04, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  12% 21.0M/182M [00:00<00:03, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  19% 21.0M/113M [00:00<00:02, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  37% 41.9M/113M [00:00<00:01, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  19% 41.9M/222M [00:00<00:04, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  46% 52.4M/115M [00:01<00:01, 38.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  28% 62.9M/222M [00:01<00:03, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'liveportrait_animals/base_models/warping_module.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models/Kiu2mTGiqawQvwJIysiPiwdDHsY=.c9719ea184ca9da059f4eee8a8c8c7c6bd46a2b1e40a241ea5490cc42ce6b79b.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  17% 31.5M/182M [00:00<00:03, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  28% 31.5M/113M [00:00<00:01, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  47% 52.4M/113M [00:01<00:01, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   0% 0.00/182M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  24% 52.4M/222M [00:01<00:03, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  55% 62.9M/115M [00:01<00:01, 40.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  33% 73.4M/222M [00:01<00:03, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  23% 41.9M/182M [00:00<00:03, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  37% 41.9M/113M [00:00<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  56% 62.9M/113M [00:01<00:01, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   6% 10.5M/182M [00:00<00:04, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  28% 62.9M/222M [00:01<00:03, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  64% 73.4M/115M [00:01<00:01, 40.8MB/s]\u001b[ADownloading 'liveportrait_animals/base_models_v1.1/appearance_feature_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models_v1.1/w2JquOgGo_-zOZp03SpATaJOQmc=.7e320d545579caa83c7b094cef8b7b43fe92a2e410c219ffa97b08be549f45bf.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth:   0% 0.00/3.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:01<00:00, 2.10MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models_v1.1/appearance_feature_extractor.pth\n",
            "Downloading 'liveportrait_animals/base_models_v1.1/motion_extractor.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models_v1.1/K0D9rBQicolH41TOWUpuFUb_e4U=.827d0ea4c56ff252dba50feece3bc62ced365ecae5edb86db07eb71b2f39a696.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  38% 83.9M/222M [00:04<00:11, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   9% 10.5M/113M [00:00<00:02, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  12% 21.0M/182M [00:03<00:29, 5.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  29% 52.4M/182M [00:04<00:16, 8.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  47% 52.4M/113M [00:04<00:07, 8.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  33% 73.4M/222M [00:04<00:16, 8.91MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  65% 73.4M/113M [00:04<00:04, 8.82MB/s]\u001b[A\u001b[A\n",
            "landmark.onnx:  73% 83.9M/115M [00:04<00:03, 9.11MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  43% 94.4M/222M [00:05<00:11, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  19% 21.0M/113M [00:01<00:05, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  35% 62.9M/182M [00:04<00:10, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  17% 31.5M/182M [00:03<00:16, 9.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  47% 105M/222M [00:05<00:07, 14.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  56% 62.9M/113M [00:04<00:04, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  82% 94.4M/115M [00:05<00:01, 12.2MB/s]\u001b[A\n",
            "\n",
            "motion_extractor.pth:  75% 83.9M/113M [00:04<00:02, 11.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  38% 83.9M/222M [00:04<00:11, 12.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  28% 31.5M/113M [00:01<00:03, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  23% 41.9M/182M [00:03<00:10, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  40% 73.4M/182M [00:04<00:07, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  65% 73.4M/113M [00:04<00:02, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  84% 94.4M/113M [00:05<00:01, 15.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  52% 115M/222M [00:05<00:05, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx:  91% 105M/115M [00:05<00:00, 15.4MB/s] \u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  43% 94.4M/222M [00:05<00:08, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  37% 41.9M/113M [00:01<00:02, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  29% 52.4M/182M [00:03<00:06, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  46% 83.9M/182M [00:04<00:05, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  47% 52.4M/113M [00:01<00:01, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  75% 83.9M/113M [00:04<00:01, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  57% 126M/222M [00:05<00:04, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  35% 62.9M/182M [00:04<00:04, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth:  93% 105M/113M [00:05<00:00, 18.6MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  47% 105M/222M [00:05<00:06, 18.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  52% 94.4M/182M [00:05<00:03, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "landmark.onnx: 100% 115M/115M [00:05<00:00, 17.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  84% 94.4M/113M [00:05<00:00, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  61% 136M/222M [00:06<00:03, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  56% 62.9M/113M [00:02<00:01, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 21.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "landmark.onnx: 100% 115M/115M [00:05<00:00, 19.4MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/landmark.onnx\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 20.0MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models/motion_extractor.pth\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  58% 105M/182M [00:05<00:02, 27.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  66% 147M/222M [00:06<00:02, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  57% 126M/222M [00:05<00:03, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  65% 73.4M/113M [00:02<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'liveportrait_animals/base_models_v1.1/spade_generator.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models_v1.1/7eKjApaVmkkjxwgjxli7XtNsnxU=.6ac31a9b608f3920ec41a402b1c4e29d22007dafd79a855f204aae9307039445.incomplete'\n",
            "Downloading 'liveportrait_animals/base_models_v1.1/warping_module.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/base_models_v1.1/Kiu2mTGiqawQvwJIysiPiwdDHsY=.7dfd251dc6b3a1baefebfc658f5bb2a2c565649cdb9aa75032591e824a0bfcee.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  40% 73.4M/182M [00:04<00:04, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:   0% 0.00/222M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  71% 157M/222M [00:06<00:01, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  75% 83.9M/113M [00:02<00:00, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:   0% 0.00/182M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  63% 115M/182M [00:05<00:02, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  61% 136M/222M [00:05<00:02, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 19.8MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/base_models/motion_extractor.pth\n",
            "Fetching 20 files:  30% 6/20 [00:07<00:25,  1.82s/it]\n",
            "spade_generator.pth:   5% 10.5M/222M [00:00<00:05, 35.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  69% 126M/182M [00:05<00:01, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  84% 94.4M/113M [00:02<00:00, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  66% 147M/222M [00:06<00:02, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:   6% 10.5M/182M [00:00<00:04, 35.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  52% 94.4M/182M [00:05<00:02, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  75% 136M/182M [00:05<00:01, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  71% 157M/222M [00:06<00:01, 40.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  76% 168M/222M [00:06<00:01, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  93% 105M/113M [00:02<00:00, 44.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'liveportrait_animals/retargeting_models/stitching_retargeting_module.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/retargeting_models/PNlJHjZewqMDsCN59DNOOoYQIJw=.3652d5a3f95099141a56986aaddec92fadf0a73c87a20fac9a2c07c32b28b611.incomplete'\n",
            "\n",
            "spade_generator.pth:   9% 21.0M/222M [00:00<00:05, 38.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "stitching_retargeting_module.pth:   0% 0.00/2.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  81% 147M/182M [00:06<00:00, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  58% 105M/182M [00:05<00:02, 34.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  76% 168M/222M [00:06<00:01, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "stitching_retargeting_module.pth: 100% 2.39M/2.39M [00:01<00:00, 1.99MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/retargeting_models/stitching_retargeting_module.pth\n",
            "Downloading 'liveportrait_animals/xpose.pth' to 'pretrained_weights/.cache/huggingface/download/liveportrait_animals/VjOeoPidTrEBdSIS2lTXTeOx6ys=.bf58e5a3c4a3a017198edc69e33f89c9a37adc856fe6b1776059b2d4a524a7dd.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   0% 0.00/435M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   2% 10.5M/435M [00:00<00:10, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  80% 178M/222M [00:09<00:03, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  86% 157M/182M [00:08<00:01, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  63% 115M/182M [00:07<00:05, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  17% 31.5M/182M [00:02<00:16, 9.15MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  85% 189M/222M [00:09<00:02, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  69% 126M/182M [00:07<00:03, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  23% 41.9M/182M [00:02<00:10, 13.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:05<00:00, 20.7MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models_v1.1/motion_extractor.pth\n",
            "\n",
            "spade_generator.pth:  14% 31.5M/222M [00:03<00:23, 8.14MB/s]\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  80% 178M/222M [00:08<00:03, 11.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   5% 21.0M/435M [00:01<00:23, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  90% 199M/222M [00:09<00:01, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  75% 136M/182M [00:07<00:02, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  19% 41.9M/222M [00:03<00:15, 11.7MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  29% 52.4M/182M [00:03<00:07, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  98% 178M/182M [00:08<00:00, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  85% 189M/222M [00:09<00:02, 14.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [00:09<00:00, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  95% 210M/222M [00:10<00:00, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [00:09<00:00, 20.2MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/base_models/warping_module.pth\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  81% 147M/182M [00:08<00:01, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  24% 52.4M/222M [00:03<00:10, 15.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  90% 199M/222M [00:09<00:01, 18.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  35% 62.9M/182M [00:03<00:05, 20.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth:  99% 220M/222M [00:10<00:00, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  10% 41.9M/435M [00:01<00:15, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  28% 62.9M/222M [00:03<00:07, 20.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  86% 157M/182M [00:08<00:01, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "spade_generator.pth: 100% 222M/222M [00:10<00:00, 21.3MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait/base_models/spade_generator.pth\n",
            "Fetching 20 files:  35% 7/20 [00:10<00:30,  2.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  12% 52.4M/435M [00:01<00:12, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  95% 210M/222M [00:09<00:00, 20.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  33% 73.4M/222M [00:04<00:05, 26.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:08<00:00, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  46% 83.9M/182M [00:04<00:03, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  99% 220M/222M [00:10<00:00, 25.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  38% 83.9M/222M [00:04<00:04, 30.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  14% 62.9M/435M [00:02<00:10, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  52% 94.4M/182M [00:04<00:02, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spade_generator.pth: 100% 222M/222M [00:10<00:00, 21.9MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models/spade_generator.pth\n",
            "Fetching 20 files:  65% 13/20 [00:11<00:05,  1.39it/s]\n",
            "spade_generator.pth:  43% 94.4M/222M [00:04<00:03, 38.7MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  58% 105M/182M [00:04<00:01, 43.8MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [00:09<00:00, 20.1MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models/warping_module.pth\n",
            "Fetching 20 files:  70% 14/20 [00:11<00:03,  1.58it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  19% 83.9M/435M [00:02<00:07, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  47% 105M/222M [00:04<00:02, 41.1MB/s] \u001b[A\n",
            "\n",
            "warping_module.pth:  63% 115M/182M [00:04<00:01, 43.6MB/s]\u001b[A\u001b[A\n",
            "spade_generator.pth:  52% 115M/222M [00:04<00:02, 41.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  22% 94.4M/435M [00:02<00:08, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "warping_module.pth:  69% 126M/182M [00:04<00:01, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  24% 105M/435M [00:02<00:06, 48.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  57% 126M/222M [00:05<00:02, 42.0MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  75% 136M/182M [00:05<00:01, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  27% 115M/435M [00:03<00:06, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  61% 136M/222M [00:05<00:02, 42.2MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  81% 147M/182M [00:05<00:00, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  29% 126M/435M [00:03<00:06, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  66% 147M/222M [00:05<00:01, 42.4MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  86% 157M/182M [00:05<00:00, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  31% 136M/435M [00:03<00:06, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  71% 157M/222M [00:05<00:01, 42.7MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:05<00:00, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  34% 147M/435M [00:03<00:06, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  76% 168M/222M [00:06<00:01, 42.6MB/s]\u001b[A\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [00:06<00:00, 29.6MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models_v1.1/warping_module.pth\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  36% 157M/435M [00:04<00:06, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  80% 178M/222M [00:06<00:01, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  39% 168M/435M [00:04<00:06, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  85% 189M/222M [00:06<00:00, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  41% 178M/435M [00:04<00:05, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  90% 199M/222M [00:06<00:00, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  43% 189M/435M [00:04<00:05, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  95% 210M/222M [00:07<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  46% 199M/435M [00:05<00:05, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth: 100% 222M/222M [00:07<00:00, 30.3MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/base_models_v1.1/spade_generator.pth\n",
            "Fetching 20 files:  85% 17/20 [00:14<00:02,  1.31it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  48% 210M/435M [00:05<00:05, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  51% 220M/435M [00:05<00:05, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  53% 231M/435M [00:05<00:04, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  55% 241M/435M [00:06<00:04, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  58% 252M/435M [00:06<00:04, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  60% 262M/435M [00:06<00:04, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  63% 273M/435M [00:06<00:03, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  65% 283M/435M [00:07<00:03, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  67% 294M/435M [00:07<00:03, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  70% 304M/435M [00:07<00:03, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  72% 315M/435M [00:07<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  75% 325M/435M [00:08<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  77% 336M/435M [00:08<00:02, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  80% 346M/435M [00:08<00:02, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  82% 357M/435M [00:08<00:01, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  84% 367M/435M [00:09<00:01, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  87% 377M/435M [00:09<00:01, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  89% 388M/435M [00:09<00:01, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  92% 398M/435M [00:09<00:00, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  94% 409M/435M [00:10<00:00, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  96% 419M/435M [00:10<00:00, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  99% 430M/435M [00:10<00:00, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth: 100% 435M/435M [00:10<00:00, 40.4MB/s]\n",
            "Download complete. Moving file to pretrained_weights/liveportrait_animals/xpose.pth\n",
            "Fetching 20 files: 100% 20/20 [00:19<00:00,  1.02it/s]\n",
            "/content/LivePortrait/pretrained_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py -s assets/examples/source/s9.jpg -d assets/examples/driving/d0.mp4\n"
      ],
      "metadata": {
        "id": "xA7vDKH5gW3v",
        "outputId": "e61ec441-c897-47cf-d315-1962aa7e5440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LivePortrait/src/utils/helper.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=lambda storage, loc: storage))\n",
            "\u001b[2;36m[14:13:49]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from                        \u001b]8;id=557692;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=723672;file:///content/LivePortrait/src/live_portrait_wrapper.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mappearance_feature_extractor.pth\u001b[0m done.                   \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[14:13:50]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                                    \u001b]8;id=487368;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=417910;file:///content/LivePortrait/src/live_portrait_wrapper.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mmotion_extractor.pth\u001b[0m done.                               \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[14:13:51]\u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                                      \u001b]8;id=737371;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=260942;file:///content/LivePortrait/src/live_portrait_wrapper.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mwarping_module.pth\u001b[0m done.                                 \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[14:13:52]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                                     \u001b]8;id=819751;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=695327;file:///content/LivePortrait/src/live_portrait_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mspade_generator.pth\u001b[0m done.                                \u001b[2m                           \u001b[0m\n",
            "/content/LivePortrait/src/utils/helper.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from                        \u001b]8;id=9359;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=897384;file:///content/LivePortrait/src/live_portrait_wrapper.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/retarge\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mting_models/\u001b[0m\u001b[95mstitching_retargeting_module.pth\u001b[0m done.            \u001b[2m                           \u001b[0m\n",
            "\u001b[1;31m2025-02-12 14:13:52.654356198 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2025-02-12 14:13:52.721824279 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m220s                               \u001b]8;id=527461;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=918180;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2025-02-12 14:13:53.145135548 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[14:13:53]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m115s                            \u001b]8;id=240971;file:///content/LivePortrait/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=337531;file:///content/LivePortrait/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad source image from assets/examples/source/s9.jpg         \u001b]8;id=105563;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=794373;file:///content/LivePortrait/src/live_portrait_pipeline.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad driving video from: assets/examples/driving/d0.mp4,    \u001b]8;id=395521;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=327844;file:///content/LivePortrait/src/live_portrait_pipeline.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mFPS is \u001b[1;36m25\u001b[0m                                                   \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStart making driving motion template\u001b[33m...\u001b[0m                     \u001b]8;id=554359;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967935;file:///content/LivePortrait/src/live_portrait_pipeline.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KMaking motion templates... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25h\u001b[2;36m[14:14:10]\u001b[0m\u001b[2;36m \u001b[0mDump motion template to assets/examples/driving/d0.pkl      \u001b]8;id=106909;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=137328;file:///content/LivePortrait/src/live_portrait_pipeline.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mPrepared pasteback mask done.                               \u001b]8;id=79332;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=741509;file:///content/LivePortrait/src/live_portrait_pipeline.py#183\u001b\\\u001b[2m183\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m[14:14:11]\u001b[0m\u001b[2;36m \u001b[0mThe animated video consists of \u001b[1;36m78\u001b[0m frames.                   \u001b]8;id=529081;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=622423;file:///content/LivePortrait/src/live_portrait_pipeline.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KAnimating... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:14\u001b[0m\n",
            "\u001b[2KConcatenating result... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[14:14:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32mAnimated template: assets/examples/driving/d0.pkl, you can \u001b[0m \u001b]8;id=70438;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=606738;file:///content/LivePortrait/src/live_portrait_pipeline.py#503\u001b\\\u001b[2m503\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mspecify `-d` argument with this template path next time to \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mavoid cropping video, motion making and protecting privacy.\u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video: animations/s9--d0.mp4                       \u001b]8;id=705440;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=217468;file:///content/LivePortrait/src/live_portrait_pipeline.py#504\u001b\\\u001b[2m504\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video with concat: animations/s9--d0_concat.mp4    \u001b]8;id=844783;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=892891;file:///content/LivePortrait/src/live_portrait_pipeline.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py\n"
      ],
      "metadata": {
        "id": "4A_FPbqylB4v",
        "outputId": "9bfaaddc-2ceb-43a8-b645-9d6e145edcdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LivePortrait/src/utils/helper.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=lambda storage, loc: storage))\n",
            "\u001b[2;36m[14:40:09]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from                        \u001b]8;id=372879;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=106765;file:///content/LivePortrait/src/live_portrait_wrapper.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mappearance_feature_extractor.pth\u001b[0m done.                   \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[14:40:10]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                                    \u001b]8;id=876785;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=156913;file:///content/LivePortrait/src/live_portrait_wrapper.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mmotion_extractor.pth\u001b[0m done.                               \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                                      \u001b]8;id=243133;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=894411;file:///content/LivePortrait/src/live_portrait_wrapper.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mwarping_module.pth\u001b[0m done.                                 \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[14:40:11]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                                     \u001b]8;id=104131;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=859296;file:///content/LivePortrait/src/live_portrait_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/base_mo\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mdels/\u001b[0m\u001b[95mspade_generator.pth\u001b[0m done.                                \u001b[2m                           \u001b[0m\n",
            "/content/LivePortrait/src/utils/helper.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from                        \u001b]8;id=274478;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=999312;file:///content/LivePortrait/src/live_portrait_wrapper.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/liveportrait/retarge\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mting_models/\u001b[0m\u001b[95mstitching_retargeting_module.pth\u001b[0m done.            \u001b[2m                           \u001b[0m\n",
            "\u001b[1;31m2025-02-12 14:40:11.588635736 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2025-02-12 14:40:11.615591999 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m206s                               \u001b]8;id=422195;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=279184;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2025-02-12 14:40:11.930443719 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[14:40:12]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m118s                            \u001b]8;id=963209;file:///content/LivePortrait/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=905553;file:///content/LivePortrait/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "* Running on local URL:  http://127.0.0.1:8890\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}